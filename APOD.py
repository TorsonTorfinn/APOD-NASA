import requests
import streamlit as st
from datetime import date
import json
from translate import Translator 
import re 
import os

# –ß—Ç–µ–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –∏–∑ JSON-—Ñ–∞–π–ª–∞
with open('translations.json', 'r', encoding='utf-8') as file:
    translations = json.load(file)

# API –∫–ª—é—á –∏–∑ secrets.toml
API_KEY = st.secrets["general"]["api_key"]

base_url = f"https://api.nasa.gov/planetary/apod"

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º (–ø–æ —Ç–æ—á–∫–∞–º)
def split_by_sentences(text):
    return re.split(r'(?<=[.!?]) +', text)  # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –ø–æ —Ç–æ—á–∫–∞–º, –≤–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º –∏–ª–∏ –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º –∑–Ω–∞–∫–∞–º

# –í—ã–±–æ—Ä —è–∑—ã–∫–∞ –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏
selected_language = st.sidebar.selectbox("üåé Select Language | –í—ã–±–µ—Ä–∏—Ç–µ —è–∑—ã–∫", ['en', 'ru'], index=0)
t = translations[selected_language]  # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–∞ –Ω–∞ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —è–∑—ã–∫–µ

# –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
st.sidebar.header(t['select_language'])
st.title(t['header'])

# –í—ã–±–æ—Ä —Ä–µ–∂–∏–º–∞ –∑–∞–ø—Ä–æ—Å–∞
query_mode = st.sidebar.radio(t['select_mode'], [t['single_image'], t['date_range'], t['random_images']])

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∂–∏–º–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞
if query_mode == t['single_image']:
    selected_date = st.sidebar.date_input(t['select_date'], date.today())
    adop_url = f"{base_url}?api_key={API_KEY}&date={selected_date}"

elif query_mode == t['date_range']:
    start_date = st.sidebar.date_input(t['start_date'], date.today().replace(day=1))
    end_date = st.sidebar.date_input(t['end_date'], date.today())
    if start_date > end_date:
        st.sidebar.error(t['image_warning'])
    adop_url = f"{base_url}?api_key={API_KEY}&start_date={start_date}&end_date={end_date}"

elif query_mode == t['random_images']:
    count = st.sidebar.slider(t['number_of_images'], min_value=1, max_value=10, value=1)
    adop_url = f"{base_url}?api_key={API_KEY}&count={count}"

# –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –∫ API
st.sidebar.markdown(f"[–ó–∞–ø—Ä–æ—Å –∫ NASA]({adop_url})")
r1 = requests.get(adop_url)

if r1.status_code != 200:
    st.error(t['api_error'])
else:
    data = r1.json()

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —è–∑—ã–∫, –Ω–∞ –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å
    target_language = 'ru' if selected_language == 'ru' else 'en'
    translator = Translator(to_lang=target_language)  # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ü–µ–ª–µ–≤–æ–π —è–∑—ã–∫ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞
    if isinstance(data, dict):
        img_title = data.get('title', t['header'])
        img_explanation = data.get('explanation', t['explanation'])
        img_url = data.get('url', '')
        media_type = data.get('media_type', 'image')
        author = data.get('copyright', t['author'])

        # –ü–µ—Ä–µ–≤–æ–¥ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏ –ø–æ—è—Å–Ω–µ–Ω–∏—è, –µ—Å–ª–∏ –≤—ã–±—Ä–∞–Ω —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫
        if target_language == 'ru':
            img_title = translator.translate(img_title)

            # –†–∞–∑–±–∏–µ–Ω–∏–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏ –ø–µ—Ä–µ–≤–æ–¥ –∫–∞–∂–¥–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
            explanation_sentences = split_by_sentences(img_explanation)
            img_explanation_translated = ' '.join([translator.translate(sentence) for sentence in explanation_sentences])
        else:
            img_explanation_translated = img_explanation

        st.subheader(img_title)
        if author:
            st.write(f"{t['author']}: {author}")
        if media_type == "video":
            st.video(img_url)
        else:
            image_path = 'image.png'
            r2 = requests.get(img_url)
            with open(image_path, 'wb') as image_file:
                image_file.write(r2.content)
            st.image(image_path)
        st.info(f"{t['explanation']}: {img_explanation_translated}")
    else:
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ø–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –¥–∞—Ç –∏–ª–∏ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –≤—ã–±–æ—Ä–∞
        for item in data:
            img_title = item.get('title', t['header'])
            img_explanation = item.get('explanation', t['explanation'])
            img_url = item.get('url', '')
            media_type = item.get('media_type', 'image')
            author = item.get('copyright', t['author'])

            # –ü–µ—Ä–µ–≤–æ–¥ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏ –ø–æ—è—Å–Ω–µ–Ω–∏—è
            if target_language == 'ru':
                img_title = translator.translate(img_title)
                
                # –†–∞–∑–±–∏–µ–Ω–∏–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏ –ø–µ—Ä–µ–≤–æ–¥ –∫–∞–∂–¥–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                explanation_sentences = split_by_sentences(img_explanation)
                img_explanation_translated = ' '.join([translator.translate(sentence) for sentence in explanation_sentences])
            else:
                img_explanation_translated = img_explanation

            st.header(img_title)
            if author:
                st.write(f"{t['author']}: {author}")
            if media_type == "video":
                st.video(img_url)
            else:
                r2 = requests.get(img_url)
                # –ü–æ–ª—É—á–∞–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞
                project_dir = os.path.dirname(os.path.abspath(__file__))
                image_dir = os.path.join(project_dir, 'images')

                # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É images, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                if not os.path.exists(image_dir):
                    os.makedirs(image_dir)

                image_path = os.path.join(image_dir, f"image_{img_title}.png")

                with open(image_path, 'wb') as image_file:
                    image_file.write(r2.content)

                st.image(image_path)
            st.info(f"{t['explanation']}: {img_explanation_translated}")
